{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np # Moved here from later in the cell, and ensured no double import.\n",
    "\n",
    "# !pip install torch torchvision transformers datasets accelerate evaluate\n",
    "# !pip install opencv-python pillow matplotlib\n",
    "\n",
    "from transformers import Mask2FormerForUniversalSegmentation\n",
    "from transformers import AutoImageProcessor\n",
    "import torch\n",
    "\n",
    "model_name = \"facebook/mask2former-swin-base-ade-semantic\"\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "from google.colab import files\n",
    "print(\"Upload ROOM image:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "from PIL import Image\n",
    "# import numpy as np # Already imported at the top\n",
    "\n",
    "image = Image.open(list(uploaded.keys())[0]).convert(\"RGB\")\n",
    "image\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "result = processor.post_process_semantic_segmentation(\n",
    "    outputs,\n",
    "    target_sizes=[image.size[::-1]]\n",
    ")[0]\n",
    "\n",
    "segmentation_map = result.cpu().numpy()\n",
    "\n",
    "model.config.id2label\n",
    "WALL_ID = 0\n",
    "FLOOR_ID = 3\n",
    "\n",
    "wall_mask = (segmentation_map == WALL_ID).astype(np.uint8) * 255\n",
    "floor_mask = (segmentation_map == FLOOR_ID).astype(np.uint8) * 255\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(wall_mask, cmap=\"gray\")\n",
    "plt.title(\"Wall Mask\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(floor_mask, cmap=\"gray\")\n",
    "plt.title(\"Floor Mask\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "from google.colab import files\n",
    "print(\"Upload Tile image:\")\n",
    "uploaded_tile = files.upload()\n",
    "\n",
    "tile_img = Image.open(list(uploaded_tile.keys())[0]).convert(\"RGB\")\n",
    "tile_img\n",
    "\n",
    "# import numpy as np # Already imported at the top\n",
    "\n",
    "tile_np = np.array(tile_img)\n",
    "room_h, room_w = image.size[1], image.size[0]\n",
    "\n",
    "tile_h, tile_w = tile_np.shape[:2]\n",
    "\n",
    "repeat_y = room_h // tile_h + 1\n",
    "repeat_x = room_w // tile_w + 1\n",
    "\n",
    "big_tile = np.tile(tile_np, (repeat_y, repeat_x, 1))\n",
    "big_tile = big_tile[:room_h, :room_w]\n",
    "\n",
    "room_np = np.array(image)\n",
    "\n",
    "floor_mask_bool = floor_mask.astype(bool)\n",
    "\n",
    "result_img = room_np.copy()\n",
    "result_img[floor_mask_bool] = big_tile[floor_mask_bool]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(result_img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Tile Applied to Floor\")\n",
    "plt.show()\n",
    "\n",
    "# import cv2 # Already imported at the top\n",
    "# import numpy as np # Already imported at the top\n",
    "\n",
    "def create_tile_pattern(width, height, tile_img, tile_size=120, grout=3):\n",
    "\n",
    "    grout_color = 220\n",
    "    pattern = np.ones((height, width, 3), dtype=np.uint8) * grout_color\n",
    "\n",
    "    tile_resized = cv2.resize(tile_img, (tile_size-grout, tile_size-grout))\n",
    "\n",
    "    for y in range(0, height, tile_size):\n",
    "        for x in range(0, width, tile_size):\n",
    "\n",
    "            variation = 0.95 + 0.1*np.random.rand()\n",
    "            tile_var = np.clip(tile_resized * variation, 0, 255).astype(np.uint8)\n",
    "\n",
    "            y_end = min(y+tile_size-grout, height)\n",
    "            x_end = min(x+tile_size-grout, width)\n",
    "\n",
    "            pattern[y:y_end, x:x_end] = tile_var[:y_end-y, :x_end-x]\n",
    "\n",
    "    return pattern\n",
    "\n",
    "def order_points_clockwise(pts):\n",
    "\n",
    "    rect = np.zeros((4,2), dtype=\"float32\")\n",
    "\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]  # top-left\n",
    "    rect[2] = pts[np.argmax(s)]  # bottom-right\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]  # top-right\n",
    "    rect[3] = pts[np.argmax(diff)]  # bottom-left\n",
    "\n",
    "    return rect\n",
    "def get_floor_corners(mask):\n",
    "\n",
    "    mask = (mask > 0).astype(np.uint8) * 255\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Convex hull (important!)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "\n",
    "    epsilon = 0.02 * cv2.arcLength(hull, True)\n",
    "    approx = cv2.approxPolyDP(hull, epsilon, True)\n",
    "\n",
    "    if len(approx) < 4:\n",
    "        return None\n",
    "\n",
    "    pts = approx.reshape(-1, 2)\n",
    "\n",
    "    # If more than 4 points, take extreme 4 via bounding quad\n",
    "    if len(pts) > 4:\n",
    "        rect = cv2.minAreaRect(hull)\n",
    "        pts = cv2.boxPoints(rect)\n",
    "\n",
    "    pts = order_points_clockwise(pts)\n",
    "\n",
    "    return np.float32(pts)\n",
    "def extract_lighting(original_img):\n",
    "    gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (51,51), 0)\n",
    "    lighting = gray_blur / 255.0\n",
    "    return lighting\n",
    "\n",
    "# Removed redundant and mis-indented imports of numpy and cv2 from here.\n",
    "\n",
    "# Convert PIL to OpenCV format\n",
    "image = np.array(image)\n",
    "\n",
    "# Convert RGB (PIL) â†’ BGR (OpenCV)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Convert PIL Image to numpy array (RGB)\n",
    "tile_img_np = np.array(tile_img)\n",
    "# Convert RGB (numpy) to BGR (OpenCV)\n",
    "tile_img_cv = cv2.cvtColor(tile_img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def apply_realistic_tile(original_img, mask, tile_img, rotation_angle=0):\n",
    "    H, W = original_img.shape[:2]\n",
    "    mask = (mask > 0).astype(np.uint8) * 255\n",
    "\n",
    "    # Get floor corners from your existing function\n",
    "    dst_pts = get_floor_corners(mask)\n",
    "\n",
    "    if dst_pts is None:\n",
    "        print(\"Could not detect proper floor corners\")\n",
    "        return original_img\n",
    "\n",
    "    # --- OPTION 2: BETTER SOURCE POINT MAPPING ---\n",
    "    # We create a much larger source plane to ensure we aren't \"zooming in\"\n",
    "    # too much on a small texture, which causes blurriness.\n",
    "    tex_scale = 800  # Decreased to make tiles appear larger/more visible\n",
    "    src_pts = np.float32([\n",
    "        [0, 0],\n",
    "        [tex_scale, 0],\n",
    "        [tex_scale, tex_scale],\n",
    "        [0, tex_scale]\n",
    "    ])\n",
    "\n",
    "    # Create the pattern based on the tex_scale\n",
    "    tile_pattern = create_tile_pattern(tex_scale, tex_scale, tile_img, tile_size=100) # Adjusted tile_size for visibility\n",
    "\n",
    "    # Apply Rotation to the source points\n",
    "    center = (tex_scale / 2, tex_scale / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "\n",
    "    # Expand src_pts to (4, 1, 2) for cv2.transform\n",
    "    rotated_src_pts = cv2.transform(src_pts.reshape(-1, 1, 2), rot_mat).reshape(-1, 2)\n",
    "\n",
    "    # Compute homography and warp\n",
    "    H_matrix = cv2.getPerspectiveTransform(rotated_src_pts, dst_pts)\n",
    "    warped_tiles = cv2.warpPerspective(tile_pattern, H_matrix, (W, H), flags=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    # --- OPTION 3: REFINED LIGHTING & BLENDING ---\n",
    "    # Extract lighting but prevent it from turning the tiles black/gray\n",
    "    gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Smaller kernel (15,15) preserves contact shadows (occlusion) better than (31,31)\n",
    "    lighting = cv2.GaussianBlur(gray, (15, 15), 0).astype(np.float32) / 255.0\n",
    "\n",
    "    # Lift the shadows: ensures tiles in dark areas are still visible\n",
    "    # Formula: 0.4 (base brightness) + 0.6 (room lighting)\n",
    "    lighting = 0.4 + (0.6 * lighting)\n",
    "\n",
    "    # Apply lighting to the warped texture\n",
    "    realistic_tiles = warped_tiles.astype(np.float32) * lighting[:, :, None]\n",
    "    realistic_tiles = np.clip(realistic_tiles, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Sharp mask blending\n",
    "    # Using a slight blur on the mask edge (3,3) prevents jagged \"pixel\" edges\n",
    "    # without making the floor look like it's glowing.\n",
    "    mask_blur = cv2.GaussianBlur(mask, (3, 3), 0) / 255.0\n",
    "    mask_3 = np.stack([mask_blur] * 3, axis=-1)\n",
    "\n",
    "    # Final Composite\n",
    "    result = (original_img.astype(np.float32) * (1 - mask_3) + \n",
    "              realistic_tiles.astype(np.float32) * mask_3).astype(np.uint8)\n",
    "\n",
    "    return result\n",
    "result_rotated = apply_realistic_tile(image, floor_mask, tile_img_cv, rotation_angle=20)\n",
    "#result_rotated = apply_realistic_tile(image, wall_mask, tile_img_cv, rotation_angle=-10)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(cv2.cvtColor(result_rotated, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Tile Applied to Floor\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
